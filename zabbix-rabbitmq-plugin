#!/usr/bin/env python

import yaml, os, pycurl, sys, argparse, json, time, urllib, sqlite3, logging, datetime
from StringIO import StringIO

def cacheConnect():
    try:
        return sqlite3.connect('%s/zabbix-rabbitmq-cache.db' % (os.path.dirname(os.path.realpath(__file__))))
    except Exception, e:
        print "There was an error connecting to the cache database."
        print str(e)
        sys.exit()


def zabbix_fail():

    print "ZBX_NOTSUPPORTED"
    sys.exit(1)


def getConfigs():

    try:

        stream = open("%s/config.yml" % (os.path.dirname(os.path.realpath(__file__))), "r")
        return yaml.load(stream)

    except Exception, e:

        print "Could not find the config.yml file."
        sys.exit(1)


def callApi(path, host, port, username, password):

    buffer = StringIO()
    url = 'http://%s:%s%s' % (host,str(port), path)

    c = pycurl.Curl()
    c.setopt(c.URL, url)
    c.setopt(c.WRITEFUNCTION, buffer.write)
    c.setopt(c.CONNECTTIMEOUT,5)
    c.setopt(c.TIMEOUT,5)
    c.setopt(c.HTTPAUTH, c.HTTPAUTH_BASIC)
    c.setopt(c.USERPWD, username + ':' + password)

    try:

        c.perform()

    except pycurl.error as e:

        logging.error('The server couldn\'t perform request for "%s": %s' % (url,str(e)))


    if c.getinfo(c.HTTP_CODE) == 200:

        body = buffer.getvalue()
        return json.loads(str(body))
        c.close()

    else:

        logging.error('Returned code was not 200: %i' % (c.getinfo(pycurl.HTTP_CODE)))
        zabbix_fail()


def main():

    parser=argparse.ArgumentParser()
    parser.add_argument('--hostname', required=True, help='the hostname of the rabbitmq server')
    parser.add_argument('--log-level', required=False, default="ERROR",choices=['DEBUG','INFO','ERROR','WARN'], help='the hostname of the rabbitmq server')
    subparsers=parser.add_subparsers(dest="command")
    discover_sub=subparsers.add_parser("discover")
    discover_sub.add_argument('--single-node-metrics', action='store_true')
    discover_group = discover_sub.add_mutually_exclusive_group()
    discover_group.add_argument('--queues', action='store_true')
    discover_group.add_argument('--cluster-nodes', action='store_true')
    check_sub=subparsers.add_parser("check")
    check_sub_method=check_sub.add_subparsers(dest="check_method")
    check_sub_method_queue=check_sub_method.add_parser("queue")
    check_sub_method_queue.add_argument('--vhost')
    check_sub_method_queue.add_argument('--name')
    check_sub_method_queue.add_argument('--metric', required=True)
    check_sub_method_node=check_sub_method.add_parser("node")
    check_sub_method_node.add_argument('--name')
    check_sub_method_node.add_argument('--metric', required=True)
    args = parser.parse_args()
    configs = getConfigs()
    logging.basicConfig(filename='%s/zabbix-rabbitmq.log' % (os.path.dirname(os.path.realpath(__file__))), level=logging.getLevelName(args.log_level))

    username = None
    password = None
    port = None
    ttl = None

    try:

        ttl = configs['defaults']['ttl']

    except:

        ttl = 15

    try:

        port = configs['hosts'][args.hostname]['port']

    except:

        try:

            port = configs['defaults']['port']

        except:

            port = 15672

    try:

        username = configs['hosts'][args.hostname]['username']

    except:

        try:

            username = configs['defaults']['username']

        except:

            username = "guest"

    try:

        password = configs['hosts'][args.hostname]['password']

    except:

        try:

            password = configs['defaults']['password']

        except:

            password = "guest"


    if args.command == "discover":

        if args.queues:

            queues = []
            queuesFound = callApi('/api/queues', args.hostname, port, username, password)

            for queue in queuesFound:

                queues.append({'{#HOSTNAME}' : args.hostname, '{#VHOSTNAME}': queue['vhost'], '{#QUEUENAME}': queue['name']})

            print json.dumps({'data': queues})

        if args.cluster_nodes:

            nodes = []
            nodesFound = None

            if args.single_node_metrics:

                nodesFound = callApi('/api/overview', args.hostname, port, username, password)
                nodes.append({'{#HOSTNAME}' : args.hostname, '{#NODENAME}':  nodesFound['node'].replace('@','__')  })

            else:

                nodesFound = callApi('/api/nodes', args.hostname, port, username, password)

                for node in nodesFound:

                    nodes.append({'{#HOSTNAME}' : args.hostname, '{#NODENAME}': node['name'].replace('@','__') })

            print json.dumps({'data': nodes})


    if args.command == "check":

        logging.info('%s - checking  %s %s %s' % (datetime.datetime.now().isoformat(), args.check_method, args.name, args.metric))

        cache = None 
        url = None
	data = None

        conn = cacheConnect()
        cur = conn.cursor()
	
        if args.check_method == "queue":

            url = '/api/queues/%s' % (urllib.quote_plus(args.vhost))

	    cache = cur.execute("SELECT * FROM CACHE WHERE hostname = ? and method = ? and vhost = ?", (args.hostname, args.check_method, args.vhost)).fetchone()

            if not cache:
            	data = callApi(url, args.hostname, port, username, password)
            	cur.execute("INSERT INTO CACHE (id,hostname,method,timestamp,vhost) values (NULL,?,?,0,?)", (args.hostname, args.check_method,args.vhost))
            	conn.commit()

        if args.check_method == "node":

            url = '/api/nodes'

	    cache = cur.execute("SELECT * FROM CACHE WHERE hostname = ? and method = ?", (args.hostname, args.check_method)).fetchone()

            if not cache:
            	data = callApi(url, args.hostname, port, username, password)
            	cur.execute("INSERT INTO CACHE (id,hostname,method,timestamp) values (NULL,?,?,0)" , (args.hostname, args.check_method))
            	conn.commit()

        if cache and ( int( time.time() ) - cache[4] ) > ttl:

            data = callApi(url, args.hostname, port, username, password)

            if args.check_method == "queue":
            	cur.execute("UPDATE CACHE SET TIMESTAMP=?, DATA=?, VHOST=? WHERE HOSTNAME=? AND METHOD=? AND VHOST=?", (int( time.time() ), json.dumps(data).replace("'","''"), args.vhost, args.hostname, args.check_method, args.vhost))
            	conn.commit()

            if args.check_method == "node":
            	cur.execute("UPDATE CACHE SET TIMESTAMP=?, DATA=? WHERE HOSTNAME=? AND METHOD=?", (int( time.time() ), json.dumps(data).replace("'","''"), args.hostname, args.check_method))
            	conn.commit()

	elif cache:
           data = json.loads(cache[3])

        conn.close()
        metric_parts = args.metric.split('.')
        metric_name = None


        if args.check_method == "node":
            metric_name = args.name.replace('__','@',2)
        else:
            metric_name = args.name

        item_list = [ item for item in data if item['name']==metric_name ]

        if not item_list or item_list[0] is None:

            logging.error('the %s name was not found: %s' % (str(args.check_method),str(args.name)))
            zabbix_fail()

        data = item_list[0]

        try:

            while len(metric_parts):

                data = data[metric_parts.pop(0)]

        except Exception as e:

            if args.metric.split('.')[0] == "message_stats" and not args.metric.split('.')[-1].endswith("_details"):

                print 0
                sys.exit()

            else:

                logging.error('the %s metric was not found or is an object' % (str(args.metric)))
                zabbix_fail()

        logging.info('%s - returning %s %s %s: %s' % (datetime.datetime.now().isoformat(), str(args.check_method), str(args.name), str(args.metric), str(data)))
        print data

if __name__ == "__main__": main()


